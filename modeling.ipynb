{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4975aee7-20ff-4666-a7a6-883d1cefb31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "620c2bdf-ae32-46b9-866f-c846ef305555",
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('./Audiobooks_train_data.npz')\n",
    "train_inputs = npz['inputs'].astype(np.float64)\n",
    "train_targets = npz['targets'].astype(np.int64)\n",
    "\n",
    "npz = np.load('./Audiobooks_validation_data.npz')\n",
    "validation_inputs = npz['inputs'].astype(np.float64)\n",
    "validation_targets =  npz['targets'].astype(np.int64)\n",
    "\n",
    "npz = np.load('./Audiobooks_test_data.npz')\n",
    "test_inputs =  npz['inputs'].astype(np.float64)\n",
    "test_targets =  npz['targets'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a8a1506-8b73-4315-b2db-0274832713a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 - 1s - loss: 0.6052 - accuracy: 0.7016 - val_loss: 0.4614 - val_accuracy: 0.8702 - 527ms/epoch - 15ms/step\n",
      "Epoch 2/100\n",
      "36/36 - 0s - loss: 0.3853 - accuracy: 0.8754 - val_loss: 0.3378 - val_accuracy: 0.8781 - 68ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "36/36 - 0s - loss: 0.3164 - accuracy: 0.8846 - val_loss: 0.3027 - val_accuracy: 0.8915 - 67ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "36/36 - 0s - loss: 0.2959 - accuracy: 0.8905 - val_loss: 0.2845 - val_accuracy: 0.8993 - 65ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "36/36 - 0s - loss: 0.2829 - accuracy: 0.8947 - val_loss: 0.2751 - val_accuracy: 0.8982 - 63ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "36/36 - 0s - loss: 0.2750 - accuracy: 0.8983 - val_loss: 0.2653 - val_accuracy: 0.9049 - 63ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "36/36 - 0s - loss: 0.2695 - accuracy: 0.8983 - val_loss: 0.2609 - val_accuracy: 0.9038 - 64ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "36/36 - 0s - loss: 0.2623 - accuracy: 0.9028 - val_loss: 0.2555 - val_accuracy: 0.9072 - 67ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "36/36 - 0s - loss: 0.2583 - accuracy: 0.9016 - val_loss: 0.2531 - val_accuracy: 0.9049 - 63ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "36/36 - 0s - loss: 0.2552 - accuracy: 0.9030 - val_loss: 0.2472 - val_accuracy: 0.9105 - 67ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "36/36 - 0s - loss: 0.2515 - accuracy: 0.9042 - val_loss: 0.2463 - val_accuracy: 0.9094 - 65ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "36/36 - 0s - loss: 0.2487 - accuracy: 0.9036 - val_loss: 0.2431 - val_accuracy: 0.9094 - 68ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "36/36 - 0s - loss: 0.2465 - accuracy: 0.9061 - val_loss: 0.2406 - val_accuracy: 0.9083 - 73ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "36/36 - 0s - loss: 0.2440 - accuracy: 0.9075 - val_loss: 0.2403 - val_accuracy: 0.9094 - 74ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "36/36 - 0s - loss: 0.2430 - accuracy: 0.9078 - val_loss: 0.2371 - val_accuracy: 0.9094 - 74ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "36/36 - 0s - loss: 0.2456 - accuracy: 0.9064 - val_loss: 0.2365 - val_accuracy: 0.9105 - 65ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "36/36 - 0s - loss: 0.2430 - accuracy: 0.9086 - val_loss: 0.2374 - val_accuracy: 0.9105 - 71ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "36/36 - 0s - loss: 0.2404 - accuracy: 0.9072 - val_loss: 0.2335 - val_accuracy: 0.9128 - 75ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "36/36 - 0s - loss: 0.2368 - accuracy: 0.9106 - val_loss: 0.2320 - val_accuracy: 0.9150 - 67ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "36/36 - 0s - loss: 0.2360 - accuracy: 0.9120 - val_loss: 0.2296 - val_accuracy: 0.9116 - 63ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "36/36 - 0s - loss: 0.2346 - accuracy: 0.9123 - val_loss: 0.2294 - val_accuracy: 0.9128 - 62ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "36/36 - 0s - loss: 0.2342 - accuracy: 0.9114 - val_loss: 0.2292 - val_accuracy: 0.9150 - 65ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "36/36 - 0s - loss: 0.2335 - accuracy: 0.9148 - val_loss: 0.2273 - val_accuracy: 0.9139 - 65ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "36/36 - 0s - loss: 0.2327 - accuracy: 0.9109 - val_loss: 0.2266 - val_accuracy: 0.9139 - 71ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "36/36 - 0s - loss: 0.2296 - accuracy: 0.9148 - val_loss: 0.2252 - val_accuracy: 0.9150 - 75ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "36/36 - 0s - loss: 0.2323 - accuracy: 0.9131 - val_loss: 0.2251 - val_accuracy: 0.9172 - 75ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "36/36 - 0s - loss: 0.2295 - accuracy: 0.9139 - val_loss: 0.2317 - val_accuracy: 0.9161 - 69ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "36/36 - 0s - loss: 0.2321 - accuracy: 0.9134 - val_loss: 0.2252 - val_accuracy: 0.9195 - 66ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2472de947f0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 10\n",
    "output_size = 2\n",
    "hidden_layer_size = 50\n",
    "batch_size = 100\n",
    "max_epochs  = 100\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation = 'relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(output_size,activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_inputs,\n",
    "          train_targets,\n",
    "          batch_size = batch_size,\n",
    "          epochs = max_epochs,\n",
    "          callbacks=[early_stopping],\n",
    "          validation_data = (validation_inputs,validation_targets),\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dffd7920-e933-4358-866b-3046ff683bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:\n",
      "Loss = 0.226\n",
      "Accuracy = 0.915\n"
     ]
    }
   ],
   "source": [
    "(loss,accuracy) = model.evaluate(test_inputs,test_targets,verbose=False)\n",
    "print(f'Test:\\nLoss = {loss:0.3f}\\nAccuracy = {accuracy:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d192d681-76a1-459f-a483-02c290ecd3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./audiobooks_dataset_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./audiobooks_dataset_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd05c522-56a4-408c-a221-516c88027c06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
